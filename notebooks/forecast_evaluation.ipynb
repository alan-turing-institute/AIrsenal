{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson\n",
    "\n",
    "from airsenal.framework.bpl_interface import get_ratings_dict\n",
    "from airsenal.framework.schema import Result, session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the team level model vs. a baseline\n",
    "\n",
    "Our baseline will be an independent poisson model, where the rates in the distribution of home and away goals are set by the mean values in the training data. All teams are treated equally.\n",
    "\n",
    "We will compare this baseline to the plain BPL model that doesn't use Fifa features, and to the BPL model that does use Fifa features.\n",
    "\n",
    "We train models on the 15/16 season and test on the 16/17 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_df():\n",
    "    \"\"\"\n",
    "    query the match table and put results into pandas dataframe,\n",
    "    to train the team-level model.\n",
    "    \"\"\"\n",
    "    df_past = pd.DataFrame(\n",
    "        np.array(\n",
    "            [\n",
    "                [\n",
    "                    s.fixture.date,\n",
    "                    s.fixture.home_team,\n",
    "                    s.fixture.away_team,\n",
    "                    s.home_score,\n",
    "                    s.away_score,\n",
    "                ]\n",
    "                for s in session.query(Result).all()\n",
    "            ]\n",
    "        ),\n",
    "        columns=[\"date\", \"home_team\", \"away_team\", \"home_goals\", \"away_goals\"],\n",
    "    )\n",
    "    df_past[\"home_goals\"] = df_past[\"home_goals\"].astype(int)\n",
    "    df_past[\"away_goals\"] = df_past[\"away_goals\"].astype(int)\n",
    "    df_past[\"date\"] = pd.to_datetime(df_past[\"date\"])\n",
    "    df_past = df_past[df_past[\"date\"] > \"2015-08-01\"]\n",
    "    return df_past.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_result_df()\n",
    "df_train = df[df[\"date\"] < \"2017-08-10\"]\n",
    "df_test = df[(df[\"date\"] >= \"2017-08-10\") & (df[\"date\"] < \"2018-08-10\")]\n",
    "df_X = get_ratings_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel:\n",
    "    def __init__(self, df):\n",
    "        self.results = df\n",
    "        self.mu_home = df[\"home_goals\"].mean()\n",
    "        self.mu_away = df[\"away_goals\"].mean()\n",
    "\n",
    "    def log_score(self, df_test):\n",
    "        home_probs = poisson.pmf(df_test[\"home_goals\"].values, self.mu_home)\n",
    "        away_probs = poisson.pmf(df_test[\"away_goals\"].values, self.mu_away)\n",
    "        return np.sum(np.log(home_probs) + np.log(away_probs)) / len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineModel(df_train)\n",
    "baseline_score = baseline.log_score(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bpl.BPLModel(data=df_train)\n",
    "model.fit(max_date=\"2017-08-10\")\n",
    "\n",
    "model.add_new_team(\"HUD\")\n",
    "model.add_new_team(\"BHA\")\n",
    "plain_score = model.log_score(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_X = bpl.BPLModel(data=df_train, X=df_X)\n",
    "model_X.fit(max_date=\"2017-08-10\")\n",
    "\n",
    "model_X.add_new_team(\n",
    "    \"HUD\",\n",
    "    X=np.ravel(\n",
    "        df_X.loc[df_X[\"team\"] == \"HUD\", [\"att\", \"mid\", \"defn\", \"ovr\"]].values\n",
    "    ).astype(float),\n",
    ")\n",
    "model_X.add_new_team(\n",
    "    \"BHA\",\n",
    "    X=np.ravel(\n",
    "        df_X.loc[df_X[\"team\"] == \"HUD\", [\"att\", \"mid\", \"defn\", \"ovr\"]].values\n",
    "    ).astype(float),\n",
    ")\n",
    "fifa_score = model_X.log_score(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Baseline model achieves a score of {baseline_score:.2f}\")\n",
    "print(f\"BPL model achieves a score of {plain_score:.2f}\")\n",
    "print(f\"BPL model  with fifa features achieves a score of {fifa_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranks of the models is as expected, with the BPL model with fifa features scoring best on holdout data. However, the difference between the two BPL models is markedly smaller than between the simpler BPL model and the baseline. Presumably the main difference comes from the matches involving Brighton and Huddersfield, where the fifa features model will perform better. Let's briefly check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hud_bha = df_test[\n",
    "    (df_test[\"home_team\"] == \"BHA\")\n",
    "    | (df_test[\"home_team\"] == \"HUD\")\n",
    "    | (df_test[\"away_team\"] == \"BHA\")\n",
    "    | (df_test[\"away_team\"] == \"BHA\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score = baseline.log_score(df_hud_bha)\n",
    "plain_score = model.log_score(df_hud_bha)\n",
    "fifa_score = model_X.log_score(df_hud_bha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Baseline model achieves a score of {baseline_score:.2f}\")\n",
    "print(f\"BPL model achieves a score of {plain_score:.2f}\")\n",
    "print(f\"BPL model  with fifa features achieves a score of {fifa_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in performance is not as much as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    sns.distplot(model_X.beta_a[:, i], label=df_X.columns[1:][i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    sns.distplot(model_X.beta_b[:, i], label=df_X.columns[1:][i])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifa features provide weak information about the defensive aptitude of a team, but not the attacking aptitude."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cba876b14047f97c1a6c0683be37bfa58dede36bf5bd1964bf1c47d5ea6251d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
