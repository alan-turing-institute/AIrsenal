{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cdcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GW1_START_DATES = {\n",
    "    2022: datetime(2022, 8, 4),\n",
    "    2023: datetime(2023, 8, 10),\n",
    "    2024: datetime(2024, 8, 15),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48befec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_map = {\n",
    "    \"Monday\": 0,\n",
    "    \"Tuesday\": 1,\n",
    "    \"Wednesday\": 2,\n",
    "    \"Thursday\": 3,\n",
    "    \"Friday\": 4,\n",
    "    \"Saturday\": 5,\n",
    "    \"Sunday\": 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6505d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekdays_between(start, end, day_of_week=\"Thursday\"):\n",
    "    \"\"\"Generate all Thursdays between two dates.\"\"\"\n",
    "    days = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        if current.weekday() == day_map[day_of_week]:\n",
    "            days = [*days, current]\n",
    "        current += timedelta(days=1)\n",
    "    return days\n",
    "\n",
    "\n",
    "def get_gameweek_number(date, gw1_start):\n",
    "    \"\"\"Calculate gameweek number based on first GW start.\"\"\"\n",
    "    delta_days = (date - gw1_start).days\n",
    "    gw = delta_days // 7 + 1\n",
    "    return gw if gw > 0 else None\n",
    "\n",
    "\n",
    "def list_articles_for_date(date: datetime):\n",
    "    base_url = f\"https://www.fantasyfootballscout.co.uk/{date.year}/{date.strftime('%m')}/{date.strftime('%d')}/\"\n",
    "    try:\n",
    "        res = requests.get(base_url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Find all anchor tags with hrefs\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        urls = set()\n",
    "\n",
    "        for link in links:\n",
    "            href = link[\"href\"]\n",
    "            if href.startswith(base_url):\n",
    "                urls.add(href)\n",
    "\n",
    "        # filter to urls containing 'injury'\n",
    "        urls = [url for url in urls if \"injury\" in url or \"team-news\" in url]\n",
    "        urls = [url for url in urls if \"comments\" not in url]\n",
    "\n",
    "        return sorted(urls)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch or parse {base_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scrape_article(url):\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        content_div = soup.find(\"article\")\n",
    "        if not content_div:\n",
    "            return None\n",
    "        paragraphs = content_div.find_all(\"p\")\n",
    "        return \"\\n\\n\".join(\n",
    "            p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0877bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "# for each year\n",
    "for season_year, gw1_date in GW1_START_DATES.items():\n",
    "    print(season_year)\n",
    "    season_end = datetime(season_year + 1, 5, 31)\n",
    "    thursdays = get_weekdays_between(gw1_date, season_end)\n",
    "    saturdays = get_weekdays_between(gw1_date, season_end, \"Saturday\")\n",
    "    update_dates = thursdays + saturdays\n",
    "    for date in tqdm(update_dates):\n",
    "        gw = get_gameweek_number(date, gw1_date)\n",
    "\n",
    "        if gw is None or gw > 38:\n",
    "            continue\n",
    "\n",
    "        urls = list_articles_for_date(date)\n",
    "\n",
    "        day_of_week = date.strftime(\"%A\")\n",
    "\n",
    "        for url in urls:\n",
    "            content = scrape_article(url)\n",
    "            if content:\n",
    "                articles.append(\n",
    "                    {\n",
    "                        \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "                        \"gameweek\": gw,\n",
    "                        \"day_of_week\": day_of_week,\n",
    "                        \"url\": url,\n",
    "                        \"content\": content,\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54763496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(by=\"date\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45494c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airsenalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
